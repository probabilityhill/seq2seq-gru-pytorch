# seq2seq-gru-pytorch
PyTorchのGRUを用いたseqence-to-seqence

## 用いたデータ
以下の夢野久作の作品を[青空文庫](https://www.aozora.gr.jp/index.html)より入手
+ [ビルディング](https://www.aozora.gr.jp/cards/000096/card915.html)
+ [線路](https://www.aozora.gr.jp/cards/000096/card46697.html)
+ [ナンセンス](https://www.aozora.gr.jp/cards/000096/card2127.html)
+ [微笑](https://www.aozora.gr.jp/cards/000096/card2379.html)
+ [スランプ](https://www.aozora.gr.jp/cards/000096/card2134.html)

＊データは「訓練用：文生成用 = 9：1」に分割

## 準備
+ textフォルダの中に、文章を分かち書きしてpickle化したものを入れる（[こちら](https://qiita.com/probabilityhill/items/86795d4d5b9b865bf1f8)を参照）
+ imgフォルダの作成

## パラメータ
```:py
EMBEDDING_DIM = HIDDEN_DIM = 256
BATCH_SIZE=50
```

## 入力例
```
Enter the number of pickle files: 5
Enter the name of file1: building
Enter the name of file2: senro
Enter the name of file3: nonsense
Enter the name of file4: hohoemi
Enter the name of file5: slump
```

## 学習結果
![loss](https://user-images.githubusercontent.com/74280232/160275444-22ac1279-1fa3-4f80-87d3-2113b5b7a4ff.jpg)
```
0%|          | 0/500 [00:00<?, ?it/s]
--------------------
epoch: 20
train_loss: 4.118, ppl: 61.414
--------------------
epoch: 40
train_loss: 2.779, ppl: 16.096
--------------------
epoch: 60
train_loss: 1.780, ppl: 5.931
--------------------
epoch: 80
train_loss: 1.091, ppl: 2.977
--------------------
epoch: 100
train_loss: 0.667, ppl: 1.949
--------------------
epoch: 120
train_loss: 0.429, ppl: 1.536
--------------------
epoch: 140
train_loss: 0.278, ppl: 1.320
--------------------
epoch: 160
train_loss: 0.187, ppl: 1.206
--------------------
epoch: 180
train_loss: 0.137, ppl: 1.147
--------------------
epoch: 200
train_loss: 0.103, ppl: 1.109
--------------------
epoch: 220
train_loss: 0.079, ppl: 1.082
--------------------
epoch: 240
train_loss: 0.062, ppl: 1.064
--------------------
epoch: 260
train_loss: 0.050, ppl: 1.052
--------------------
epoch: 280
train_loss: 0.043, ppl: 1.044
--------------------
epoch: 300
train_loss: 0.036, ppl: 1.037
--------------------
epoch: 320
train_loss: 0.031, ppl: 1.032
--------------------
epoch: 340
train_loss: 0.027, ppl: 1.028
--------------------
epoch: 360
train_loss: 0.025, ppl: 1.025
--------------------
epoch: 380
train_loss: 0.023, ppl: 1.023
--------------------
epoch: 400
train_loss: 0.021, ppl: 1.021
--------------------
epoch: 420
train_loss: 0.019, ppl: 1.019
--------------------
epoch: 440
train_loss: 0.017, ppl: 1.018
--------------------
epoch: 460
train_loss: 0.015, ppl: 1.015
--------------------
epoch: 480
train_loss: 0.014, ppl: 1.014
--------------------
epoch: 500
train_loss: 0.013, ppl: 1.013

```

## 文生成例
元の文と同じものが多いが、新しい文も生成される。（学習のレベルによると思われる）
```
四つも五つも電話が鳴りはためいている中でも平気で辷っていたペンが、蠅の羽音を聞いても停電するようになりました。
--------------------------------------------------
ほどイヤなお提灯記事、御機嫌取り記事、尻拭い原稿なぞいうものを、電話や靴の音がガンガンガタガタと入り乱れるバラックの二階で、一気に、伸び伸びと書き飛ばし得る神経になり切っていたのです。
--------------------------------------------------
だしているうちに頭を向けて、私の寝姿を鏡に映したように正反対の方向に足を伸ばしつつ、スヤスヤと睡りかけているのだ。
--------------------------------------------------
今でも可笑しいと思っているのですから、私はソモソモになってしまったのです。
--------------------------------------------------
何よりも私のペンの我ままが、絶頂に達したものと考えるのが、今の私の気持ちに一番ピッタリしているのです。
--------------------------------------------------
同時に「猟奇趣味」という言葉も甚だアイマイなように感じている。
--------------------------------------------------
真黒に肩を怒らした機関車を先に立てて、囚人のようにつながって来る貨物車の群れが見える。
--------------------------------------------------
万一そうとすれば、それこそ一大事です。
--------------------------------------------------
何もかもバラバラになったまま、可愛らしくニコニコしていたペンが、蠅の羽音を聞いても停電するようになりました。
--------------------------------------------------
考える力もないくらい睡むたがっている。
--------------------------------------------------
何もかもバラバラになったまま、可愛らしくニコニコしていた。
--------------------------------------------------
ボール紙あいだ御下命の原稿、一度、御猶予願っておきながら、まだ書けずにおります。
--------------------------------------------------
「馬鹿……」と私は思わず口走りつつ、唾をペッとその死骸の上に吐きかけた。
--------------------------------------------------
同時に「猟奇趣味」という言葉も甚だアイマイなように感じている。
--------------------------------------------------
そのスベスベした肌の光りが無性に悲しく、腹立たしく、自烈度くなった。
--------------------------------------------------
そこで又、着のみ着のまま家を飛出して、地図も何も持たないまま、盲目滅法に野山を歩るきまわる。
--------------------------------------------------
四つも五つも電話が鳴りはためいている中でも平気で辷っていたペンが、蠅の羽音を聞いても停電するようになりました。
--------------------------------------------------
しかし、又、万一それがそうでなかったらどうであろう。
--------------------------------------------------
どうしたらこの苦境を通り抜ける事が出来るでしょう。
--------------------------------------------------
「人知れず失恋していたのだ」位のことはおしまいに言うかも知れぬ。
--------------------------------------------------
淋しさが、しかし、私の死姿を探偵か新聞記者が上った音……。
--------------------------------------------------
私はガバと跳ね起きた。
--------------------------------------------------
```

## 参考
+ [NLP From Scratch: Translation with a Sequence to Sequence Network and Attention — PyTorch Tutorials 1.11.0+cu102 documentation](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)
+ [【Pytorch入門】ニュース記事で文章生成がしたい - Qiita](https://qiita.com/hcpmiyuki/items/c6afc037518542cfe410)
+ [PyTorchでSeq2Seqを実装してみた - Qiita](https://qiita.com/m__k/items/b18756628575b177b545)
+ [PyTorchによるSeq2seqの実装 - どん底から這い上がるまでの記録](https://www.pytry3g.com/entry/pytorch-seq2seq#%E3%83%86%E3%82%B9%E3%83%88%E3%81%99%E3%82%8B)
+ [PyTorchによる言語モデルの作り方 - どん底から這い上がるまでの記録](https://www.pytry3g.com/entry/PyTorch%E3%81%A7%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB#%E6%96%87%E5%8D%98%E4%BD%8D%E3%81%A7%E3%81%AE%E5%AE%9F%E8%A3%85)
